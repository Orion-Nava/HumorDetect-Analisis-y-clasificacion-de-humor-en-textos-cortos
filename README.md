# Clasificaci√≥n de humor en textos cortos con modelos estad√≠sticos

Este proyecto tiene como objetivo analizar y predecir si un texto corto es humor√≠stico o no, utilizando t√©cnicas de procesamiento de lenguaje natural (NLP) y modelos estad√≠sticos cl√°sicos de clasificaci√≥n.

---

## üì¶ Dataset

Se utiliz√≥ el dataset [200K Short Texts for Humor Detection](https://www.kaggle.com/datasets/deepcontractor/200k-short-texts-for-humor-detection) disponible en Kaggle. Contiene m√°s de 200,000 textos cortos en ingl√©s etiquetados como `humor=True` o `humor=False`.

- **Variables clave:**
  - `text`: contenido del texto.
  - `humor`: variable binaria que indica si el texto es humor√≠stico (`True`) o no (`False`).

---

## üéØ Objetivos

1. Realizar un an√°lisis exploratorio del lenguaje humor√≠stico.
2. Preprocesar los textos y aplicar t√©cnicas de vectorizaci√≥n (TF-IDF).
3. Entrenar y evaluar distintos modelos de clasificaci√≥n:
   - Regresi√≥n log√≠stica
   - Naive Bayes
   - Random Forest
4. Comparar su rendimiento con m√©tricas como accuracy, matriz de confusi√≥n y curvas de aprendizaje.
5. Extraer conclusiones sobre el comportamiento ling√º√≠stico del humor.

---

## üß™ Preprocesamiento y vectorizaci√≥n

- Se eliminaron caracteres no alfab√©ticos y se normaliz√≥ el texto (min√∫sculas, sin acentos).
- Se eliminaron stopwords en ingl√©s.
- Se eliminaron los n√∫meros, por considerarse poco informativos para este caso.
- Se aplic√≥ `TfidfVectorizer` para convertir los textos en vectores num√©ricos. Se prob√≥ con distintos tama√±os del vocabulario (`max_features=50`, `15000`, etc.).

---

## ü§ñ Modelos implementados

### 1. Regresi√≥n log√≠stica
Modelo lineal que predice la probabilidad de que un texto sea humor√≠stico a partir de los valores TF-IDF de sus palabras.

### 2. Naive Bayes (MultinomialNB)
Clasificador probabil√≠stico basado en el teorema de Bayes, que asume independencia entre palabras. Funciona sorprendentemente bien en tareas de clasificaci√≥n de texto.

### 3. Random Forest
Modelo de conjunto basado en √°rboles de decisi√≥n. Fue probado con una versi√≥n reducida del vocabulario debido a limitaciones computacionales.

---

## üìä Evaluaci√≥n y resultados

Se usaron m√©tricas est√°ndar para evaluar el rendimiento:

- **Accuracy general** de los modelos: ~0.90
- **Precision y Recall**:
  - Textos humor√≠sticos: ~89-91%
  - Textos no humor√≠sticos: ~88-91%
- Las **curvas de aprendizaje** mostraron un buen comportamiento en todos los modelos, con mejoras consistentes a medida que aumentaba el tama√±o del conjunto de entrenamiento.

---

## ‚úÖ Conclusiones

- El modelo de regresi√≥n log√≠stica ofreci√≥ el mejor rendimiento general, aunque Naive Bayes lo sigui√≥ muy de cerca.
- Random Forest tuvo un rendimiento competitivo, pero fue computacionalmente m√°s costoso.
- El uso de preprocesamiento (eliminaci√≥n de stopwords, n√∫meros, etc.) ayud√≥ a reducir el ruido y mejorar la generalizaci√≥n.
- El humor parece tener una estructura ling√º√≠stica recurrente, lo que facilit√≥ su detecci√≥n mediante modelos estad√≠sticos cl√°sicos.

---

## üìÇ Archivos incluidos

- `An√°lisis exploratorio profundo del humor textual.ipynb`: an√°lisis exploratorio, frecuencias y visualizaci√≥n.
- `Modelos estad√≠sticos para predecir si un texto es humor√≠stico.ipynb`: vectorizaci√≥n y clasificaci√≥n.
- `dataset (b).csv`: dataset procesado con columnas a√±adidas.

---

## üöÄ Pr√≥ximos pasos

- Aplicar embeddings (Word2Vec, GloVe, BERT).
- Implementar modelos de redes neuronales.
- Ampliar el an√°lisis al nivel de n-gramas o dependencias gramaticales.

---

## ‚úçÔ∏è Autor

Josu√© Nava ‚Äî Estudiante de la Licenciatura en Estad√≠stica, Universidad Aut√≥noma Chapingo

---

